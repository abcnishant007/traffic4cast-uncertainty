{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files: format from Alex:\n",
    "# speed:  [0, 2, 4, 6] \n",
    "# volume: [1, 3, 5, 7]\n",
    "#  (samples, 4, 495, 436, 8), where in second dim: \n",
    "#         0: ground truth, \n",
    "#         1: point prediction, \n",
    "#         2: epistemic uncertainty, \n",
    "#         3: aleatoric uncertainty\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from smartprint import smartprint as sprint\n",
    "\n",
    "model_list = [\"unet\", \"unetpp\"]\n",
    "foldername_prefix = \"h5_files_\"\n",
    "city_list = [\"moscow\", \"antwerp\"] \n",
    "\n",
    "for model in model_list:\n",
    "    for city in city_list:\n",
    "        filename = os.path.join(foldername_prefix + model, \"pred_combo_\" + city + \".h5\") \n",
    "\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            a_group_key = list(f.keys())[0]\n",
    "            data = list(f[a_group_key])\n",
    "            sprint (len(data))\n",
    "            \n",
    "            for i in tqdm(range(len(data)), desc=\"Reading \" + model + city):\n",
    "                sample = data[i]\n",
    "#                 sprint (sample.shape); break  # if just checking the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "\n",
    "smoothing_window = 1000 # 1000 is a reasonable window considering the number of points \\\n",
    "                        # to be around 200K +. It can be increased even more; Plus we use valid padding\n",
    "                        # whenever smoothing, so that no edge effects distort our view of the plots\n",
    "\n",
    "chan = {\"GT\":0, \"PP\":1, \"EU\":2, \"AU\":3}\n",
    "\n",
    "speed_channels = [0, 2, 4, 6]  # [4,5,6,7] # [0,1,2,3] # [1, 3, 5, 7]\n",
    "volume_channels = [1, 3, 5, 7] # [0,1,2,3] # [4,5,6,7] # [0, 2, 4, 6]\n",
    "\n",
    "density_label_flag = False\n",
    "speed_thresh_low = 0.1\n",
    "for model in model_list[:]:    \n",
    "    for city in city_list[:]:\n",
    "        filename = os.path.join(foldername_prefix + model, \"pred_combo_\" + city + \".h5\") \n",
    "\n",
    "        X = []\n",
    "        Y = [] \n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            a_group_key = list(f.keys())[0]\n",
    "            data = list(f[a_group_key])\n",
    "            sprint (len(data))\n",
    "            density_proxy = []\n",
    "            sample_sum = 0 \n",
    "            for i in tqdm(range(len(data))): #range(len(data)), desc=\"reading all files for one city\"):\n",
    "                sample = data[i]\n",
    "                sample_sum += sample\n",
    "        sample = sample_sum / len(data)\n",
    "        \n",
    "        sprint (sample.shape)\n",
    "        \n",
    "        volume_gt = sample[chan[\"GT\"], :, :, volume_channels]\n",
    "        volume_pred = sample[chan[\"PP\"], :, :, volume_channels]\n",
    "        volume_unc_a = sample[chan[\"AU\"], :, :, volume_channels]\n",
    "        volume_unc_e = sample[chan[\"EU\"], :, :, volume_channels]\n",
    "        \n",
    "        speed_gt = sample[chan[\"GT\"], :, :, speed_channels]\n",
    "        speed_pred = sample[chan[\"PP\"], :, :, speed_channels]\n",
    "        speed_unc_a = sample[chan[\"AU\"], :, :, speed_channels]\n",
    "        speed_unc_e = sample[chan[\"EU\"], :, :, speed_channels]        \n",
    "\n",
    "        non_zero_speed = speed_gt > 0\n",
    "\n",
    "        density_gt = volume_gt/speed_gt\n",
    "        non_zero_density = density_gt > 0\n",
    "\n",
    "        valid_indices = non_zero_density & non_zero_speed\n",
    "\n",
    "        sprint (speed_gt.shape, non_zero_speed.shape, valid_indices.shape, density_gt.shape)\n",
    "        sprint (volume_gt.shape, speed_gt.shape)\n",
    "        speed_gt = speed_gt[valid_indices].tolist()\n",
    "        speed_pred = speed_pred[valid_indices].tolist()\n",
    "        speed_unc_a = speed_unc_a[valid_indices].tolist()\n",
    "        speed_unc_e = speed_unc_e[valid_indices].tolist()\n",
    "\n",
    "        volume_gt = volume_gt[valid_indices].tolist()\n",
    "        volume_pred = volume_pred[valid_indices].tolist()\n",
    "        volume_unc_a = volume_unc_a[valid_indices].tolist()\n",
    "        volume_unc_e = volume_unc_e[valid_indices].tolist()\n",
    "\n",
    "        density_gt = density_gt[valid_indices].tolist()\n",
    "                \n",
    "        \n",
    "\n",
    "        ############ Same thing with absolute values of quantiles on the xticks\n",
    "        def sort_two_lists_according_to_first(X,Y):\n",
    "            ss = sorted(zip(X, Y))\n",
    "            X = [x for x, y in ss]\n",
    "            Y = [y for x, y in ss]    \n",
    "            return X, Y\n",
    "\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X, _ = sort_two_lists_according_to_first(density_gt, speed_gt)\n",
    "        plt.plot(X[smoothing_window//2:-smoothing_window//2], label=\"density\")    \n",
    "\n",
    "        names = ['speed_gt', 'speed_unc_a', 'speed_unc_e', 'volume_unc_a', 'volume_gt', 'volume_unc_e']\n",
    "        for index, var in enumerate([speed_gt, speed_unc_a, speed_unc_e, volume_unc_a, volume_gt, volume_unc_e]):\n",
    "            _, Y = sort_two_lists_according_to_first(density_gt, var)\n",
    "            Y = Y[smoothing_window//2:-smoothing_window//2]\n",
    "\n",
    "            plt.plot(np.convolve(Y, [1/smoothing_window]*smoothing_window, \"same\"), label=names[index])\n",
    "        #     plt.show()\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        pos = np.array([0.0, 25.0, 50.0, 75.0, 95.0])\n",
    "        perc = np.round(np.percentile(X, p), 2)\n",
    "\n",
    "        plt.xticks(((len(X)-1) * pos/100), map(str, perc))\n",
    "        \n",
    "        plt.xlabel(\"Density proxy quantiles\")\n",
    "        plt.ylabel(\"Absolute values\")\n",
    "        plt.legend()\n",
    "        plt.title(slugify(model+\"_\"+city))\n",
    "        plt.show()\n",
    "        sprint (len(var))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sort_two_lists_according_to_first(X,Y):\n",
    "    ss = sorted(zip(X, Y))\n",
    "    X = [x for x, y in ss]\n",
    "    Y = [y for x, y in ss]    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "smoothing_window = 1101\n",
    "\n",
    "\n",
    "X, _ = sort_two_lists_according_to_first(density_gt, speed_gt)\n",
    "plt.plot(X[smoothing_window//2:-smoothing_window//2], label=\"density\")    \n",
    "\n",
    "names = ['speed_gt', 'speed_err', 'speed_unc', 'volume_err', 'volume_gt', 'volume_unc']\n",
    "for index, var in enumerate([speed_gt, speed_unc_a, speed_unc_e, volume_unc_a, volume_gt, volume_unc_e]):\n",
    "    \n",
    "    sprint (len(var))\n",
    "    _, Y = sort_two_lists_according_to_first(density_gt, var)\n",
    "    Y = Y[smoothing_window//2:-smoothing_window//2]\n",
    "    \n",
    "    plt.plot(np.convolve(Y, [1/smoothing_window]*smoothing_window, \"same\"), label=names[index])\n",
    "#     plt.show()\n",
    "plt.yscale(\"log\")\n",
    "p = np.array([0.0, 25.0, 50.0, 75.0, 100.0])\n",
    "plt.xticks(((len(X)-1) * p/100), map(str, p))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Same thing with absolute values of quantiles on the xticks\n",
    "def sort_two_lists_according_to_first(X,Y):\n",
    "    ss = sorted(zip(X, Y))\n",
    "    X = [x for x, y in ss]\n",
    "    Y = [y for x, y in ss]    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "smoothing_window = 101\n",
    "\n",
    "\n",
    "X, _ = sort_two_lists_according_to_first(density_gt, speed_gt)\n",
    "plt.plot(X[smoothing_window//2:-smoothing_window//2], label=\"density\")    \n",
    "\n",
    "names = ['speed_gt', 'speed_unc_a', 'speed_unc_e', 'volume_unc_a', 'volume_gt', 'volume_unc_e']\n",
    "for index, var in enumerate([speed_gt, speed_unc_a, speed_unc_e, volume_unc_a, volume_gt, volume_unc_e]):\n",
    "    \n",
    "    sprint (len(var))\n",
    "    _, Y = sort_two_lists_according_to_first(density_gt, var)\n",
    "    Y = Y[smoothing_window//2:-smoothing_window//2]\n",
    "    \n",
    "    plt.plot(np.convolve(Y, [1/smoothing_window]*smoothing_window, \"same\"), label=names[index])\n",
    "#     plt.show()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "pos = np.array([0.0, 25.0, 50.0, 75.0, 100.0])\n",
    "perc = np.round(np.percentile(X, p), 2)\n",
    "\n",
    "plt.xticks(((len(X)-1) * pos/100), map(str, perc))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ \n",
    "################ NO need; \n",
    "################ the above cells suffice. the cells from here onwards;\n",
    "################ are remnants of earlier trials;\n",
    "################ \n",
    "\n",
    "# ! pip install smartprint\n",
    "# ! pip install python-slugify\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from smartprint import smartprint\n",
    "from slugify import slugify\n",
    "\n",
    "def single_plot(a, y_list, density_channels, combine=\"mean\", y_pred_name=\"GT\", \\\n",
    "                speed_thresh_low=0):\n",
    "    \"\"\"\n",
    "    a : numpy array of shape (4, 495, 436, 8)\n",
    "    combine : [\"mean\", \"mean_of_square\"] # how to combine 4 channels\n",
    "    y_list : list of y channels for plot; \n",
    "    density_channels : list of x channels for plot; Both x_list and y_list are from the the fourth dimension (index=3)\n",
    "    speed_thresh_low : 0; threshold below which we ignore the density values (to avoid abnormally large values) \n",
    "\n",
    "    \"\"\"\n",
    "    chan = {\"GT\":0, \"PP\":1, \"EU\":2, \"AU\":3}\n",
    "    speed_channels = [0, 2, 4, 6]\n",
    "\n",
    "    \n",
    "    density_vals = []\n",
    "    non_zero_indices_in_density_channels = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, i in enumerate(density_channels):\n",
    "        \n",
    "        # we need to filter zeros in speed channels to avoid np.nans in the density computation\n",
    "        # The 0 in # a[0, ...] implies we are using the density computed using GT\n",
    "        where_non_zero = a[0, :, :, speed_channels[index]] > speed_thresh_low\n",
    "        \n",
    "        # we use the indices where speed was non-zero to extract the densities, otherwise\n",
    "        # we would get very high values for density\n",
    "        x = a[0, :, :, i][where_non_zero]\n",
    "\n",
    "        y = a[chan[y_pred_name], :, :, index][where_non_zero]\n",
    "\n",
    "#         non_zero_indices_in_density_channels.append(where_non_zero)\n",
    "\n",
    "#         if combine==\"mean\":\n",
    "#             density_vals.extend( x.flatten().tolist() )\n",
    "        X.extend(x.flatten().tolist())\n",
    "        Y.extend(y.flatten().tolist())\n",
    "    \n",
    "#     density_vals\n",
    "\n",
    "#     y = []\n",
    "#     #  Now, we just need to choose the correponding Y values (GT, PP, EE, AU etc. for speed)\n",
    "#     for index, i in enumerate(y_list):\n",
    "#         x = a[chan[y_pred_name], :, :, i][non_zero_indices_in_density_channels[index]]\n",
    "#         if combine==\"mean\":\n",
    "#             y .extend( x.flatten().tolist() )\n",
    "\n",
    "#     assert len(density_vals) == len(y)\n",
    "    return X, Y\n",
    "    \n",
    "\n",
    "smoothing_window = 1 # 1000 is a reasonable window considering the number of points \\\n",
    "                        # to be around 200K + \n",
    "density_label_flag = False\n",
    "speed_thresh_low = 0.1\n",
    "for model in model_list[0:1]:    \n",
    "    for city in city_list[0:1]:\n",
    "        for traffic_var in [\"Speed\", \"Volume\"][:2]:\n",
    "            for y_var in [\"GT\", \"AU\", \"EU\", \"PP\"][0:3]:                \n",
    "\n",
    "                filename = os.path.join(foldername_prefix + model, \"pred_combo_\" + city + \".h5\") \n",
    "\n",
    "                X = []\n",
    "                Y = [] \n",
    "                with h5py.File(filename, \"r\") as f:\n",
    "                    a_group_key = list(f.keys())[0]\n",
    "                    data = list(f[a_group_key])\n",
    "                    sprint (len(data))\n",
    "\n",
    "                    density_proxy = []\n",
    "                    for i in tqdm(range(20)): #range(len(data)), desc=\"reading all files for one city\"):\n",
    "                        sample = data[i]\n",
    "\n",
    "                        ss = sample.shape\n",
    "\n",
    "                        sample_with_density = np.random.rand(ss[0], ss[1], ss[2], 8 + 4) \n",
    "                        # + 4 is to store the 4 channels for the computed density\n",
    "\n",
    "                        sample_with_density[:, :, :, :8] = np.array(sample)\n",
    "                        \n",
    "                        # mean_density is used to save the density computed by taking the \n",
    "                        # mean speed and volume across all channels\n",
    "                        mean_density = np.random.rand(ss[1], ss[2]) \n",
    "\n",
    "                        for speed_channel in [0, 2, 4, 6]:\n",
    "                            vol_channel = speed_channel + 1\n",
    "\n",
    "                            # 0 in the first dimension is to because we don't care about the densities computed\n",
    "                            # from anything apart from GT channels for speed and volume, all others are set to np.nan\n",
    "                            # 8 + speed_channel//2 iterates over 8,9,10,11: The 4 channels where we store the \n",
    "                            # computed densities\n",
    "                            sample_with_density[0, :, :, 8 + speed_channel//2] = \\\n",
    "                                        sample[0, :, :, vol_channel] / sample[0, :, :, speed_channel] \n",
    "\n",
    "                            for j in range(1, 4):\n",
    "                                # all others are set to np.nan\n",
    "                                sample_with_density[j, :, :, 8 + speed_channel//2] = np.nan\n",
    "                        \n",
    "                        gt_volume = (sample[0, :, :, 1] + sample[0, :, :, 3] + \\\n",
    "                                    sample[0, :, :, 5] + sample[0, :, :, 7])/4\n",
    "                        gt_speed = (sample[0, :, :, 0] + sample[0, :, :, 2] + \\\n",
    "                                     sample[0, :, :, 4] + sample[0, :, :, 6])/4\n",
    "                        \n",
    "                        where_speed_more_than_speed_thresh = gt_speed > speed_thresh_low\n",
    "                        mean_density[:,:] = gt_volume / gt_speed\n",
    "                        mean_density = mean_density[where_speed_more_than_speed_thresh] \n",
    "                        gt_speed = gt_speed[where_speed_more_than_speed_thresh]\n",
    "                                \n",
    "                        \n",
    "    #                     sprint (sample_with_density.shape)        \n",
    "\n",
    "                        # y_list=[0,2,4,6] implies we wish to plot {AU, GT, EU, PP} w.r.t speed\n",
    "                        # if we wish to plot w.r.t volume, we need to use y_list = [1,3,5,7]\n",
    "                        y_list = {\"Speed\":[0,2,4,6], \"Volume\":[1,3,5,7]}\n",
    "                        x,y = single_plot(sample_with_density, density_channels=[8,9,10,11], \\\n",
    "                                          y_list=y_list[traffic_var], \\\n",
    "                                          combine=\"mean\", \\\n",
    "                                          y_pred_name=y_var,\\\n",
    "                                          speed_thresh_low=speed_thresh_low)\n",
    "\n",
    "                        X.extend(x)\n",
    "                        Y.extend(y)\n",
    "\n",
    "#                         X.extend(mean_density.flatten().tolist())\n",
    "#                         Y.extend(gt_speed.flatten().tolist())    \n",
    "\n",
    "                X = np.array(X)\n",
    "                Y = np.array(Y)\n",
    "                \n",
    "                X_no_nan = X[~np.isnan(X)]\n",
    "                Y_no_nan = Y[~np.isnan(X)] \n",
    "                X = X_no_nan\n",
    "                Y = Y_no_nan\n",
    "                \n",
    "                \n",
    "                maxX = X.max()\n",
    "                \n",
    "                x = X[ (X<0.9 * maxX) & (X>5) ]\n",
    "                y = Y[ (X<0.9 * maxX) & (X>5) ]\n",
    "                X = x; Y = y\n",
    "                \n",
    "                X = X.flatten().tolist()\n",
    "                Y = Y.flatten().tolist()\n",
    "                \n",
    "                ss = sorted(zip(X, Y))\n",
    "                X = [x for x, y in ss]\n",
    "                Y = [y for x, y in ss]        \n",
    "                \n",
    "                # X must be sorted\n",
    "                assert all(X[i] <= X[i+1] for i in range(len(X) - 1))\n",
    "                \n",
    "\n",
    "                padded_length = max(smoothing_window, len(X)) - min(smoothing_window, len(X)) + 1\n",
    "                # we just need the density plot once, we can just keep plotting it in the same color\n",
    "                # but no need for the label so that we don't repeat\n",
    "                if not density_label_flag:\n",
    "                    plt.plot(range(padded_length), np.convolve(X, [1/smoothing_window]*smoothing_window, \"valid\"), \\\n",
    "                         label=slugify(\"density proxy sorted\"), color=\"blue\")\n",
    "                    density_label_flag = True\n",
    "                else:\n",
    "                    plt.plot(range(padded_length), np.convolve(X, [1/smoothing_window]*smoothing_window, \"valid\"), \\\n",
    "                         color=\"blue\")  # next time, no labels\n",
    "                \n",
    "                \n",
    "                plt.plot(range(padded_length), np.convolve(Y, [1/smoothing_window]*smoothing_window, \"valid\"), \\\n",
    "                         label=y_var + \"-\" +traffic_var)\n",
    "                plt.xlabel(\"Quantiles of density proxy\")\n",
    "\n",
    "                # add quantile x-ticks\n",
    "                p = np.array([0.0, 25.0, 50.0, 75.0, 100.0])\n",
    "                plt.xticks((len(X)-1) * p/100., map(str, p))\n",
    "\n",
    "                plt.yscale(\"log\")\n",
    "                plt.legend()\n",
    "                plt.title(slugify(city + \",\" + model))\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 200, label=\"X\")\n",
    "plt.hist(Y, 200, label=\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(X)), Y, alpha=0.1)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, alpha=0.1, s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(X), np.max(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(Y[i] <= Y[i+1] for i in range(len(X) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(X), max(Y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[(X>3) & (X<4)]\n",
    "y = Y[(X>3) & (X<4)]\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install statsmodels\n",
    "from statsmodels.graphics.gofplots import qqplot_2samples\n",
    "qqplot_2samples(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
